{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Implementation\n",
    "MLflow is a comprehensive platform that can logs experiments with detailed metadata by recording parameters, metrics, model version and output artifacts, it allows to seamlessly manage the machine learning lifecycle making comparative analysis with a clear UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import mlflow\n",
    "import dagshub\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       270\n",
      "           1       0.62      0.50      0.56        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.79      0.73      0.76       300\n",
      "weighted avg       0.91      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9456521739130435,\n",
       "  'recall': 0.9666666666666667,\n",
       "  'f1-score': 0.9560439560439561,\n",
       "  'support': 270.0},\n",
       " '1': {'precision': 0.625,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.5555555555555556,\n",
       "  'support': 30.0},\n",
       " 'accuracy': 0.92,\n",
       " 'macro avg': {'precision': 0.7853260869565217,\n",
       "  'recall': 0.7333333333333334,\n",
       "  'f1-score': 0.7557997557997558,\n",
       "  'support': 300.0},\n",
       " 'weighted avg': {'precision': 0.9135869565217392,\n",
       "  'recall': 0.92,\n",
       "  'f1-score': 0.9159951159951161,\n",
       "  'support': 300.0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "report_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this case we need to restore the experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'First Experiment' has been restored.\n"
     ]
    }
   ],
   "source": [
    "# Create the MLflow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Get the experiment by its name\n",
    "experiment = client.get_experiment_by_name(\"First Experiment\")\n",
    "\n",
    "if experiment is None:\n",
    "    print(\"Experiment not found.\")\n",
    "else:\n",
    "    # Restore the experiment using its ID\n",
    "    client.restore_experiment(experiment.experiment_id)\n",
    "    print(f\"Experiment '{experiment.name}' has been restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 10:18:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run clumsy-shark-19 at: http://127.0.0.1:5000/#/experiments/247970322603174652/runs/1a073c5d913c482aa8a97ef645d11388\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/247970322603174652\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"First Experiment\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': report_dict['accuracy'],\n",
    "        'recall_class_0': report_dict['0']['recall'],\n",
    "        'recall_class_1': report_dict['1']['recall'],\n",
    "        'f1_score_macro': report_dict['macro avg']['f1-score']\n",
    "    })\n",
    "    mlflow.sklearn.log_model(lr, \"Logistic Regression\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       270\n",
      "           1       0.60      0.50      0.55        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.77      0.73      0.75       300\n",
      "weighted avg       0.91      0.92      0.91       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C=1, solver='liblinear')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       270\n",
      "           1       0.95      0.70      0.81        30\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.96      0.85      0.89       300\n",
      "weighted avg       0.97      0.97      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       270\n",
      "           1       0.96      0.80      0.87        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.97      0.90      0.93       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Handle class imbalance using SMOTETomek and then Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       270\n",
      "           1       0.81      0.83      0.82        30\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.89      0.91      0.90       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train_res, y_train_res)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Experiments Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        {\"C\": 1, \"solver\": 'liblinear'},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, params, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9814126394052045,\n",
       "  'recall': 0.9777777777777777,\n",
       "  'f1-score': 0.9795918367346939,\n",
       "  'support': 270.0},\n",
       " '1': {'precision': 0.8064516129032258,\n",
       "  'recall': 0.8333333333333334,\n",
       "  'f1-score': 0.819672131147541,\n",
       "  'support': 30.0},\n",
       " 'accuracy': 0.9633333333333334,\n",
       " 'macro avg': {'precision': 0.8939321261542151,\n",
       "  'recall': 0.9055555555555556,\n",
       "  'f1-score': 0.8996319839411174,\n",
       "  'support': 300.0},\n",
       " 'weighted avg': {'precision': 0.9639165367550067,\n",
       "  'recall': 0.9633333333333334,\n",
       "  'f1-score': 0.9635998661759786,\n",
       "  'support': 300.0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'Anomaly Detection' has been restored.\n"
     ]
    }
   ],
   "source": [
    "# Create the MLflow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Retrieve the experiment by name\n",
    "experiment = client.get_experiment_by_name(\"Anomaly Detection\")\n",
    "\n",
    "if experiment is None:\n",
    "    print(\"Experiment not found.\")\n",
    "else:\n",
    "    # Restore the experiment\n",
    "    client.restore_experiment(experiment.experiment_id)\n",
    "    print(f\"Experiment '{experiment.name}' has been restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 10:22:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/3ad4aadc67d7472da65a974825bf2656\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 10:22:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Random Forest at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/d5dca81e20c44aad8d9f748876df4efe\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 10:23:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/f2f4bf000b3f4e789060d6fa79753ddc\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 10:23:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBClassifier With SMOTE at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/69abac4306d7495aadd1e6d0c0849901\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Anomaly Detection\")\n",
    "# Look at the repository in MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })  \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Register the Model**\n",
    "\n",
    "Registering a model in MLflow is a crucial step in the machine learning lifecycle because it enables effective model versioning, management, and deployment. Here are the key reasons why registering a model is important:\n",
    "\n",
    "---\n",
    "\n",
    "**1. Centralized Model Management**\n",
    "- **Version Control:** Each registered model is automatically assigned a unique version (e.g., \"Model v1,\" \"Model v2\"). This allows you to track and manage changes as models are retrained or improved.\n",
    "- **Organization:** Centralizes all models in a registry, making it easier to manage multiple models across different projects.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Model Deployment and Serving**\n",
    "- Registered models can be directly deployed to various environments (e.g., REST API endpoints, cloud services).\n",
    "- MLflow supports **model serving**, where a registered model can be served for real-time predictions using built-in or custom MLflow environments.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Reproducibility**\n",
    "- Registering a model saves the exact version of the model along with its associated artifacts (e.g., training code, environment, parameters). This ensures that the model can be consistently reproduced across environments and users.\n",
    "\n",
    "---\n",
    "\n",
    "**4. Governance and Lifecycle Management**\n",
    "- MLflow supports managing the **lifecycle stages** of a model:\n",
    "  - `Staging`: A model is in the testing phase before being promoted to production.\n",
    "  - `Production`: The model is actively serving in production.\n",
    "  - `Archived`: The model is no longer actively used but retained for reference.\n",
    "- This stage management enables proper governance and risk control during deployment.\n",
    "\n",
    "---\n",
    "\n",
    "**5. Collaboration**\n",
    "- Teams can share and collaborate on registered models across projects and departments. This is especially useful for large organizations where multiple teams might reuse models.\n",
    "- Different team members can promote models to different stages (e.g., Data Scientists register and test the model, while DevOps promotes it to production).\n",
    "\n",
    "---\n",
    "\n",
    "**6. Experiment Comparison**\n",
    "- MLflow allows you to compare multiple model versions and registered models to evaluate performance, parameters, and metrics across experiments. This helps with selecting the best model for deployment.\n",
    "\n",
    "---\n",
    "\n",
    "**7. Integration with CI/CD Pipelines**\n",
    "- Registered models can be integrated into continuous integration/continuous deployment (CI/CD) pipelines. This helps automate the deployment process, ensuring smooth transitions from development to production.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion**\n",
    "Registering a model in MLflow is a best practice for model lifecycle management, improving collaboration, governance, reproducibility, and deployment readiness. It plays a key role in operationalizing machine learning (MLOps) and ensuring models are effectively tracked and deployed across different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGB-Classifier' already exists. Creating a new version of this model...\n",
      "2025/02/18 12:07:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGB-Classifier, version 2\n",
      "Created version '2' of model 'XGB-Classifier'.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"XGB-Classifier\"\n",
    "run_id = input(\"Enter run ID:\")\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri, model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'models\\XGB-Classifier\\challenger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model_uri = f\"models/{model_name}@challenger\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:5000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/XGB-Classifier/challenger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      8\u001b[0m y_pred[:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\mlflow\\xgboost\\__init__.py:337\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, dst_path)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_uri, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load an XGBoost model from a local file or a run.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m        models, depending on the saved model class specification.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     local_model_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     flavor_conf \u001b[38;5;241m=\u001b[39m _get_flavor_configuration(local_model_path, FLAVOR_NAME)\n\u001b[0;32m    339\u001b[0m     _add_code_from_conf_to_system_path(local_model_path, flavor_conf)\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:116\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[0;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[0;32m    115\u001b[0m     )\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sebas\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\local_artifact_repo.py:91\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[1;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[0;32m     89\u001b[0m local_artifact_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(artifact_path))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_artifact_path):\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_artifact_path)\n",
      "\u001b[1;31mOSError\u001b[0m: No such file or directory: 'models\\XGB-Classifier\\challenger'"
     ]
    }
   ],
   "source": [
    "model_name = \"XGB-Classifier\"\n",
    "model_version = 2\n",
    "model_uri = f\"models/{model_name}@challenger\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d364bddde64ca6af32d1fc911f0b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_uri = \"mlflow-artifacts:/235694836365368649/f2f4bf000b3f4e789060d6fa79753ddc/artifacts/model\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "\n",
    "# Predict using the loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition the Model to Production\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Anomaly-Detection-Prod' already exists. Creating a new version of this model...\n",
      "Copied version '2' of model 'XGB-Classifier' to version '4' of model 'Anomaly-Detection-Prod'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1739892351145, current_stage='None', description='', last_updated_timestamp=1739892351145, name='Anomaly-Detection-Prod', run_id='f2f4bf000b3f4e789060d6fa79753ddc', run_link='', source='models:/XGB-Classifier/2', status='READY', status_message=None, tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model_uri = \"models:/XGB-Classifier/2\"\n",
    "production_model_name = \"Anomaly-Detection-Prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=current_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelVersion: aliases=[], creation_timestamp=1739892351145, current_stage='None', description='', last_updated_timestamp=1739892351145, name='Anomaly-Detection-Prod', run_id='f2f4bf000b3f4e789060d6fa79753ddc', run_link='', source='models:/XGB-Classifier/2', status='READY', status_message=None, tags={}, user_id='', version='4'>,\n",
       " <ModelVersion: aliases=['production'], creation_timestamp=1739891345759, current_stage='Production', description='', last_updated_timestamp=1739891435986, name='Anomaly-Detection-Prod', run_id='f2f4bf000b3f4e789060d6fa79753ddc', run_link='', source='models:/XGB-Classifier/1', status='READY', status_message=None, tags={}, user_id='', version='3'>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_registered_model(production_model_name).latest_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1739892351145, current_stage='Production', description='', last_updated_timestamp=1739892481040, name='Anomaly-Detection-Prod', run_id='f2f4bf000b3f4e789060d6fa79753ddc', run_link='', source='models:/XGB-Classifier/2', status='READY', status_message=None, tags={}, user_id='', version='4'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition the model to production or champion stage\n",
    "client.transition_model_version_stage(\n",
    "    name=production_model_name,    # Model name\n",
    "    version=4,                      # Version of the model to promote\n",
    "    stage='Production'                # The stage to promote to\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f980913f6a24c948f0cdcd9ef262b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Production Model\n",
    "# model_version = 1\n",
    "# prod_model_uri = f\"models:/{production_model_name}@production\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "loaded_model = mlflow.xgboost.load_model(\"models:/Anomaly-Detection-Prod/Production\")\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DagsHub\n",
    "\n",
    "Combining DagsHub with MLflow creates a powerful, end-to-end ecosystem for managing your data science projects. Each tool addresses complementary aspects of the workflow, and together they provide a unified framework for version control, experiment tracking, collaboration, and reproducibility. Here‚Äôs a detailed look at the advantages:\n",
    "\n",
    "---\n",
    "\n",
    "**1. Unified Project Management**\n",
    "\n",
    "- **Version Control for Code and Data:**  \n",
    "  - **DagsHub:** Utilizes Git for code versioning and integrates with DVC (Data Version Control) to manage datasets and large files.  \n",
    "  - **Benefit:** You maintain a clear history of code changes and data modifications, ensuring that every experiment is associated with a specific state of both code and data.\n",
    "  \n",
    "- **Experiment Tracking with MLflow:**  \n",
    "  - **MLflow:** Focuses on tracking experiment parameters, metrics, and artifacts (such as models, visualizations, or logs).  \n",
    "  - **Benefit:** You get a detailed log of each experiment run, making it easier to compare and reproduce results.\n",
    "\n",
    "- **Integrated Workflow:**  \n",
    "  - **Combination Advantage:** By linking MLflow‚Äôs experiment runs to specific Git commits and DVC-tracked data snapshots on DagsHub, you achieve a high level of traceability. This means that any experiment can be traced back to the exact code and dataset version used, which is invaluable for debugging and auditing.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Enhanced Collaboration and Transparency**\n",
    "\n",
    "- **Team Collaboration:**  \n",
    "  - **DagsHub:** Provides collaborative features such as pull requests, issue tracking, and shared repositories, facilitating teamwork and code reviews.  \n",
    "  - **MLflow:** When used in tandem, the experiment tracking data becomes accessible to the team, allowing everyone to review model performance, compare experiments, and discuss improvements.\n",
    "\n",
    "- **Transparency in Model Development:**  \n",
    "  - **Benefit:** The combined setup offers a transparent view of how models evolve over time. Stakeholders can see which changes in the code or data led to improvements (or degradations) in performance, supporting better decision-making.\n",
    "\n",
    "\n",
    "**3. Seamless Transition from Research to Production**\n",
    "\n",
    "- **Model Registry and Deployment:**  \n",
    "  - **MLflow Model Registry:** Helps in managing different versions of your models, including those developed for tasks like anomaly detection.\n",
    "  - **DagsHub Integration:** With all changes tracked and versioned, transitioning a well-performing model from research to production becomes much smoother, as you can reliably reference the exact code, data, and experiment details associated with that model.\n",
    "\n",
    "- **Continuous Integration/Continuous Deployment (CI/CD):**  \n",
    "  - **Benefit:** Integrating these tools into your CI/CD pipelines ensures that improvements are automatically tested and deployed, further enhancing operational efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "By combining DagsHub and MLflow, you create an environment where every aspect of your data science project‚Äîfrom code and data management to experiment tracking and collaboration‚Äîis seamlessly integrated. This approach not only enhances reproducibility and auditability but also fosters efficient teamwork and continuous improvement, ultimately leading to more robust and reliable models in real-life projects. Whether you're developing anomaly detection systems or any other type of model, this integrated setup can significantly streamline your workflow and elevate your project management practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"SebastianGarrido2790/mlflow_dagshub_demo\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"SebastianGarrido2790/mlflow_dagshub_demo\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository SebastianGarrido2790/mlflow_dagshub_demo initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository SebastianGarrido2790/mlflow_dagshub_demo initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up DagsHub\n",
    "dagshub.init(repo_owner='SebastianGarrido2790', repo_name='mlflow_dagshub_demo', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 13:14:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/36455769418245d6a5d999c56d69d03d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 13:15:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Random Forest at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/e34cf5c0f3e74cc1ade1161ce2d42f49\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 13:15:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/575c988ea5024086a0fbf510f60d4e04\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/18 13:16:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBClassifier With SMOTE at: http://127.0.0.1:5000/#/experiments/235694836365368649/runs/a99db691e2244753bfe16207572839e4\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/235694836365368649\n"
     ]
    }
   ],
   "source": [
    "# Ideally you will not require following 4 lines if you have started fresh and do not have any previous dagshub credentials on your computer\n",
    "# import os\n",
    "# os.environ['MLFLOW_TRACKING_USERNAME'] = \"SebastianGarrido2790\"\n",
    "# os.environ['MLFLOW_TRACKING_PASSWORD'] = \"30391249ad213d2d5844a26146b6319d7b09d7ed\"\n",
    "# os.environ['MLFLOW_TRACKING_URI'] = \"https://dagshub.com/SebastianGarrido2790/mlflow_dagshub_demo.mlflow\" \n",
    "\n",
    "# Publish to our centralize Dgashub server\n",
    "mlflow.set_experiment(\"Anomaly Detection\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })  \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
